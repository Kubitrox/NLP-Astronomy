{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from spacy.training import Example\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('florida is a popular spot for photographing meteors.', {'entities': [(0, 7, 'LOC')]})\n",
      "('milky way can be seen from lake tekapo', {'entities': [(27, 38, 'LOC')]})\n",
      "('the sun can be seen from okavango delta', {'entities': [(25, 39, 'LOC')]})\n",
      "('the satellites was super obvious in the mauna keamauna kea offers a clear view of satellitesgreat mauna kea', {'entities': [(40, 49, 'LOC')]})\n",
      "('the skies over cerro paranal are ideal for photographing the orion nebula.', {'entities': [(15, 28, 'LOC')]})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class AstroNERDataset:\n",
    "    def __init__(self):\n",
    "        self.templates = [\n",
    "            \"{location} is a popular spot for photographing {astro_object}.\",\n",
    "            \"astrophotographers recommend {location} for capturing {astro_object}.\",\n",
    "            \"{location} offers some of the clearest skies for observing {astro_object}.\",\n",
    "            \"{astro_object} can often be seen clearly from {location}.\",\n",
    "            \"the skies over {location} are ideal for photographing {astro_object}.\",\n",
    "            \"many photographers visit {location} to capture {astro_object}.\",\n",
    "            \"The observatories in {location} provide excellent views of {astro_object}.\",\n",
    "            \"{astro_object} enthusiasts often gather at {location}.\",\n",
    "            \"photographing {astro_object} from {location} is an unforgettable experience.\",\n",
    "            '{astro_object} can be seen from {location}',\n",
    "            'the {location} is the 1 place on the planet for {astro_object}',\n",
    "            'the {astro_object} was super obvious in the {location}'\n",
    "            '{location} offers a clear view of {astro_object}'\n",
    "            'great {location}'\n",
    "        ]\n",
    "\n",
    "        self.locations = [\n",
    "            \"Mauna Kea\",\"Atacama\" \"Atacama Desert\",\"mauna loa\" \"Death Valley\", \"Mont MÃ©gantic\", \"Pic du Midi\",\n",
    "            \"Lake Tekapo\", \"Okavango Delta\", \"Himalayas\", \"Cerro Paranal\", \"Uluru\",\n",
    "            \"Big Bend National Park\", \"Lick Observatory\", \"Lowell Observatory\",\n",
    "             \"VLT in Chile\", \"Meteora in Greece\", \"Arcetri Astrophysical Observatory\" \"Kitt Peak\",'florida','south carolina'\n",
    "        ]\n",
    "        self.locations = [location.lower() for location in self.locations]\n",
    "\n",
    "        self.astro_objects = [\n",
    "            \"Milky Way\", \"Moon\", \"Andromeda Galaxy\", \"Stars\", \"Nebulae\", \n",
    "            \"Planets\", \"Auroras\", \"Comets\", \"Meteors\", \"Exoplanets\",\n",
    "            \"Deep-sky Objects\", \"Satellites\", \"The Sun\", \"Earth from Space\",\n",
    "            \"Jupiter and its Moons\", \"The Orion Nebula\", 'titan'\n",
    "        ]\n",
    "        self.astro_objects = [astro_object.lower() for astro_object in self.astro_objects]\n",
    "\n",
    "    \n",
    "    def generate_example(self):\n",
    "        \"\"\"Generates a single labeled training example.\"\"\"\n",
    "        template = random.choice(self.templates)\n",
    "        location = random.choice(self.locations)\n",
    "        astro_object = random.choice(self.astro_objects)\n",
    "        sentence = template.format(location=location, astro_object=astro_object)\n",
    "        # Define entities for the example\n",
    "        location_start = sentence.index(location)\n",
    "        location_end = location_start + len(location)\n",
    "        return (sentence, {\"entities\": [(location_start, location_end, \"LOC\")]})\n",
    "    \n",
    "    def generate_dataset(self, size=500):\n",
    "        \"\"\"Generates a dataset with the specified number of examples.\"\"\"\n",
    "        dataset = [self.generate_example() for _ in range(size)]\n",
    "        return dataset\n",
    "\n",
    "# Create the dataset\n",
    "astro_dataset = AstroNERDataset()\n",
    "train_data = astro_dataset.generate_dataset(size=500)\n",
    "\n",
    "# Preview a few examples\n",
    "for example in train_data[:5]:\n",
    "    print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scibert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"allenai/scibert_scivocab_uncased\"  # SciBERT model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "def get_locations(ner_pipeline, text, location_labels=None):\n",
    "    \"\"\"\n",
    "    Extract location-related entities from text using a Hugging Face NER pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    - ner_pipeline: A Hugging Face NER pipeline.\n",
    "    - text (str): Input text.\n",
    "    - location_labels (set, optional): Set of entity labels considered as locations.\n",
    "\n",
    "    Returns:\n",
    "    - locations (list): List of location names identified in the text.\n",
    "    \"\"\"\n",
    "    if location_labels is None:\n",
    "        location_labels = {\"LOC\", \"GPE\", \"FAC\"}\n",
    "\n",
    "    # Get NER results from the pipeline\n",
    "    ner_results = ner_pipeline(text)\n",
    "\n",
    "    # Extract entities that match the specified location labels\n",
    "    locations = [entity['word'] for entity in ner_results if entity['entity'] in location_labels]\n",
    "\n",
    "    return locations\n",
    "\n",
    "def process_file_s(file_path, ner_pipeline, location_labels=None, max_lines=1000):\n",
    "    \"\"\"\n",
    "    Read sentences from a file and process them using a Hugging Face NER pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the input text file.\n",
    "    - ner_pipeline: A Hugging Face NER pipeline.\n",
    "    - location_labels (set, optional): Set of entity labels considered as locations.\n",
    "    - max_lines (int, optional): Maximum number of lines to process.\n",
    "\n",
    "    Returns:\n",
    "    - recommended_locs (list): List of recommended location names identified in the text.\n",
    "    \"\"\"\n",
    "    recommended_locs = []\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i >= max_lines:\n",
    "                break\n",
    "\n",
    "            sentence = line.strip()\n",
    "            if sentence:\n",
    "                # Extract locations\n",
    "                locs = get_locations(ner_pipeline, sentence, location_labels)\n",
    "                recommended_locs.extend(locs)\n",
    "\n",
    "    return recommended_locs\n",
    "\n",
    "rec_loc_sci_s = process_file_s(\"preprocessed_comments_sentences\",ner_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model and tokenizer locally\n",
    "# model.save_pretrained(\"./local_scibert_scivocab_uncased_model\")\n",
    "# tokenizer.save_pretrained(\"./local_scibert_scivocab_uncased_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the base model\n",
    "model = spacy.load(\"en_core_web_sm\")\n",
    "ner = model.get_pipe(\"ner\")\n",
    "print(ner.labels)\n",
    "ner.add_label(\"LOC\")  # Add the label if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the satellites was super obvious in the mauna keam...\" with entities \"[(40, 49, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the moon was super obvious in the himalayashimalay...\" with entities \"[(34, 43, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the jupiter and its moons was super obvious in the...\" with entities \"[(51, 73, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the exoplanets was super obvious in the lake tekap...\" with entities \"[(40, 51, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the deep-sky objects was super obvious in the lake...\" with entities \"[(46, 57, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the meteors was super obvious in the lowell observ...\" with entities \"[(37, 55, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the auroras was super obvious in the vlt in chilev...\" with entities \"[(37, 49, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the auroras was super obvious in the mauna keamaun...\" with entities \"[(37, 46, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the planets was super obvious in the south carolin...\" with entities \"[(37, 51, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the the sun was super obvious in the lake tekapola...\" with entities \"[(37, 48, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the earth from space was super obvious in the cerr...\" with entities \"[(46, 59, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the the sun was super obvious in the mauna loadeat...\" with entities \"[(37, 58, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the auroras was super obvious in the okavango delt...\" with entities \"[(37, 51, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the exoplanets was super obvious in the floridaflo...\" with entities \"[(40, 47, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the meteors was super obvious in the big bend nati...\" with entities \"[(37, 59, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the titan was super obvious in the vlt in chilevlt...\" with entities \"[(35, 47, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the stars was super obvious in the lick observator...\" with entities \"[(35, 51, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the auroras was super obvious in the lick observat...\" with entities \"[(37, 53, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the andromeda galaxy was super obvious in the lick...\" with entities \"[(46, 62, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the jupiter and its moons was super obvious in the...\" with entities \"[(51, 63, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the jupiter and its moons was super obvious in the...\" with entities \"[(51, 60, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the planets was super obvious in the himalayashima...\" with entities \"[(37, 46, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the milky way was super obvious in the meteora in ...\" with entities \"[(39, 56, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the exoplanets was super obvious in the okavango d...\" with entities \"[(40, 54, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the milky way was super obvious in the lowell obse...\" with entities \"[(39, 57, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the exoplanets was super obvious in the south caro...\" with entities \"[(40, 54, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the nebulae was super obvious in the mont mÃ©gantic...\" with entities \"[(37, 50, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the titan was super obvious in the okavango deltao...\" with entities \"[(35, 49, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the nebulae was super obvious in the meteora in gr...\" with entities \"[(37, 54, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the moon was super obvious in the cerro paranalcer...\" with entities \"[(34, 47, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the moon was super obvious in the atacamaatacama d...\" with entities \"[(34, 55, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the planets was super obvious in the mauna loadeat...\" with entities \"[(37, 58, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the milky way was super obvious in the arcetri ast...\" with entities \"[(39, 81, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the the orion nebula was super obvious in the maun...\" with entities \"[(46, 67, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the andromeda galaxy was super obvious in the cerr...\" with entities \"[(46, 59, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the planets was super obvious in the floridaflorid...\" with entities \"[(37, 44, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gkami\\anaconda3\\envs\\openap-env\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"the titan was super obvious in the himalayashimala...\" with entities \"[(35, 44, 'LOC')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def fine_tune(model,train_data):# Convert to spaCy's Example objects\n",
    "    examples = [Example.from_dict(model.make_doc(text), ann) for text, ann in train_data]\n",
    "\n",
    "    # Fine-tune the model\n",
    "    optimizer = model.resume_training()\n",
    "    for epoch in range(10):\n",
    "        losses = {}\n",
    "        model.update(examples, drop=0.5, losses=losses)\n",
    "fine_tune(model,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.to_disk(\"fine_tuned_astro_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    \"The\", \"Mauna\", \"Kea\", \"Observatory\", \"in\", \"Hawaii\", \"offers\", \"unparalleled\", \"views\", \"of\", \"the\", \"Milky\", \"Way\", \"due\", \"to\", \"its\", \"high\", \"altitude\", \"and\", \"clear\", \"skies\", \".\",\n",
    "    \"The\", \"Atacama\", \"Desert\", \"in\", \"Chile\", \"is\", \"one\", \"of\", \"the\", \"best\", \"places\", \"on\", \"Earth\", \"for\", \"stargazing\", \",\", \"thanks\", \"to\", \"its\", \"dry\", \"climate\", \"and\", \"minimal\", \"light\", \"pollution\", \".\",\n",
    "    \"Photographers\", \"love\", \"capturing\", \"the\", \"Aurora\", \"Borealis\", \"from\", \"TromsÃ¸\", \",\", \"Norway\", \",\", \"especially\", \"during\", \"the\", \"winter\", \"months\", \"when\", \"the\", \"lights\", \"are\", \"most\", \"vivid\", \".\",\n",
    "    \"The\", \"Namib\", \"Desert\", \"in\", \"Namibia\", \"provides\", \"a\", \"spectacular\", \"view\", \"of\", \"the\", \"Southern\", \"Hemisphere\", \"'s\", \"stars\", \",\", \"with\", \"almost\", \"no\", \"artificial\", \"light\", \"interference\", \".\",\n",
    "    \"The\", \"Canary\", \"Islands\", \"are\", \"popular\", \"for\", \"astrophotography\", \",\", \"especially\", \"at\", \"the\", \"Roque\", \"de\", \"los\", \"Muchachos\", \"Observatory\", \"on\", \"La\", \"Palma\", \".\",\n",
    "    \"Utah\", \"'s\", \"Bryce\", \"Canyon\", \"National\", \"Park\", \"is\", \"a\", \"favorite\", \"for\", \"night\", \"photography\", \",\", \"offering\", \"some\", \"of\", \"the\", \"darkest\", \"skies\", \"in\", \"the\", \"United\", \"States\", \".\",\n",
    "    \"The\", \"Dark\", \"Sky\", \"Park\", \"in\", \"Cherry\", \"Springs\", \"State\", \"Park\", \",\", \"Pennsylvania\", \",\", \"is\", \"renowned\", \"for\", \"its\", \"pristine\", \"night\", \"skies\", \"and\", \"excellent\", \"stargazing\", \"opportunities\", \".\",\n",
    "    \"Mount\", \"Cook\", \"National\", \"Park\", \"in\", \"New\", \"Zealand\", \"is\", \"part\", \"of\", \"the\", \"Aoraki\", \"Mackenzie\", \"International\", \"Dark\", \"Sky\", \"Reserve\", \",\", \"making\", \"it\", \"a\", \"perfect\", \"spot\", \"for\", \"astrophotography\", \".\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = spacy.load(\"fine_tuned_astro_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = spacy.load(\"en_core_web_sm\")\n",
    "ner2 = model.get_pipe(\"ner\")\n",
    "ner2.add_label(\"LOC\")  # Add the label if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank', 'you', 'these', 'posts', 'inevitably', 'have', 'a', 'line', 'in', 'them', 'that', 'says', 'i', 'know', 'what', 'thing', 'looks', 'like', 'but', 'most', 'people', 'actually', 'do', 'not', 'so', 'here', 'is', 'a', 'quick', 'guide', 'to', 'what', 'they', 'usually', 'are', 'very', 'bright', 'star', 'not', 'moving', 'planet', 'typically', 'jupiter', 'or', 'venus', 'very', 'quick', 'flash', 'that', 'may', 'or', 'may', 'not', 'leave', 'a', 'momentary', 'trail', 'meteor', 'brighter', 'quick', 'flash', 'that', 'leaves', 'a', 'trail', 'that', 'may', 'last', 'several', 'seconds', 'bolide', 'faint', 'fuzzy', 'ball', 'with', 'or', 'without', 'tail', 'not', 'moving', 'appears', 'every', 'night', 'for', 'days', 'or', 'weeks', 'comet', 'anything', 'with', 'blinking', 'bits', 'aircraft', 'smoothly', 'moving', 'star', 'satellite', 'brighter', 'smoothly', 'moving', 'star', 'iss', 'star', 'that', 'brightens', 'for', 'a', 'moment', 'then', 'dims', 'again', 'satellite', 'flare', 'line', 'of', 'smoothly', 'moving', 'stars', 'satellite', 'train', 'starlink', 'launch', 'something', 'going', 'upwards', 'with', 'or', 'without', 'tail', 'rocket', 'launch', 'crazy', 'spiral', 'or', 'other', 'pattern', 'failed', 'rocket', 'launch', 'bunch', 'of', 'fiery', 'dots', 'with', 'trails', 'all', 'moving', 'together', 'rocket', 'debris', 'reentry', 'bunch', 'of', 'white', 'lights', 'in', 'formation', 'just', 'hanging', 'in', 'sky', 'sometimes', 'blinking', 'drone', 'test', 'fiery', 'burst', 'that', 'appears', 'and', 'disappears', 'randomly', 'hot', 'air', 'balloon', 'glowing', 'saucer', 'with', 'cow', 'hovering', 'beneath', 'it', 'aliens', 'south', 'carolina', 'atacama', 'is', 'a', 'great', 'location', 'for', 'photography', 'saw', '7', 'an', 'hour', 'also', 'only', 'watched', 'one', 'hour', 'another', 'beautiful', 'image', 'of', 'cosmic', 'proportions', 'i', 'see', 'the', 'skull', 'face', 'too', 'endless', 'wonders', 'all', 'around', 'us', 'this', 'is', 'why', 'space', 'and', 'everything', 'in', 'it', 'will', 'forever', 'have', 'endless', 'beauty', 'and', 'sights', 'that', 'draws', 'everyone', 'to', 'seek', 'what', 'else', 'lies', 'beyond', 'what', 'we', 'see', 'tnx', 'for', 'that', 'guide', 'but', 'sadly', 'the', 'object', 'i', 'saw', 'does', 'not', 'match', 'anything', 'of', 'listed', 'above', 'wow', 'skysafari', 'app', 'search', 'tonights', 'best', 'i', 'use', 'skyguide', 'but', 'i', 'will', 'check', 'it', 'out', 'andromeda', 'can', 'be', 'seen', 'from', 'florida', 'naked', 'eye', 'on', 'a', 'good', 'night', 'do', 'you', 'have', 'a', 'sky', 'app', 'on', 'your', 'phone']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "thank you\n",
    "these posts inevitably have a line in them that says i know what thing looks like but most people actually do not so here is a quick guide to what they usually are very bright star not moving planet typically jupiter or venus very quick flash that may or may not leave a momentary trail meteor brighter quick flash that leaves a trail that may last several seconds bolide faint fuzzy ball with or without tail not moving appears every night for days or weeks comet anything with blinking bits aircraft smoothly moving star satellite brighter smoothly moving star iss star that brightens for a moment then dims again satellite flare line of smoothly moving stars satellite train starlink launch something going upwards with or without tail rocket launch crazy spiral or other pattern failed rocket launch bunch of fiery dots with trails all moving together rocket debris reentry bunch of white lights in formation just hanging in sky sometimes blinking drone test fiery burst that appears and disappears randomly hot air balloon glowing saucer with cow hovering beneath it aliens\n",
    "south carolina\n",
    "atacama is a great location for photography\n",
    "saw 7 an hour\n",
    "also only watched one hour\n",
    "another beautiful image of cosmic proportions\n",
    "i see the skull face too endless wonders all around us\n",
    "this is why space and everything in it will forever have endless beauty and sights that draws everyone to seek what else lies beyond what we see\n",
    "tnx for that guide but sadly the object i saw does not match anything of listed above\n",
    "wow\n",
    "skysafari app search tonights best\n",
    "i use skyguide but i will check it out\n",
    "andromeda can be seen from florida\n",
    "naked eye on a good night\n",
    "do you have a sky app on your phone\n",
    "\"\"\"\n",
    "\n",
    "# Convert the text into a list of words\n",
    "word_list = text.split()\n",
    "\n",
    "# Print the list\n",
    "print(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rocket debris', 'south carolina']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_locations(model, tokens, max_tokens=2):\n",
    "    \"\"\"\n",
    "    Extract location-related entities from a list of tokens using a spaCy model,\n",
    "    with an optional limit on the number of tokens in each entity.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: A spaCy language model.\n",
    "    - tokens (list): List of tokens (words) from the input text.\n",
    "    - max_tokens (int, optional): Maximum number of tokens allowed in each returned entity.\n",
    "    \n",
    "    Returns:\n",
    "    - locations (list): List of location names identified in the text, \n",
    "      each with a token count less than or equal to max_tokens.\n",
    "    \"\"\"\n",
    "    doc = model(\" \".join(tokens))\n",
    "    location_labels = {\"LOC\", \"GPE\",}\n",
    "    locations = [\n",
    "        ent.text for ent in doc.ents \n",
    "        if ent.label_ in location_labels and (max_tokens is None or len(ent) <= max_tokens)\n",
    "    ]\n",
    "    return locations\n",
    "\n",
    "\n",
    "get_locations(model_t,word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_s(file_path, model):\n",
    "    \"\"\"\n",
    "    Read sentences from a file and process them using spaCy's NER.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the input text file.\n",
    "    - model: The spaCy NLP model.\n",
    "    \n",
    "    Returns:\n",
    "    - recomended_locs (list): List of extracted locations.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    recomended_locs = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        sentence = line.strip()  # Remove leading/trailing whitespace\n",
    "        if sentence:  # Skip empty lines\n",
    "            \n",
    "            \n",
    "            # Tokenize the sentence into words\n",
    "            tokens = sentence.split()  # Split the sentence into tokens\n",
    "            # Extract locations\n",
    "            loc = get_locations(model, tokens)\n",
    "            if loc:  # Check if loc is not empty\n",
    "                recomended_locs.extend(loc)\n",
    "            i += 1  \n",
    "        if i == 9000:\n",
    "            break\n",
    "    return recomended_locs\n",
    "\n",
    "\n",
    "# Example Usage: Replace 'input.txt' with your text file\n",
    "rec_loc_s = process_file_s(\"preprocessed_comments_sentences\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['south carolina', 'florida', 'jacksonville', 'georgia', 'arizona', 'new zealand', 'london', 'prague', 'uk', 'florida', 'harden', 'nina', 'phd2', 'north america', 'mount mount', 'california', 'alaska', 'michigan', 'michigan', 'earth', 'new moon', 'alabama', 'massachusetts', 'new mexico', 'earth', 'india', 'youironmaiden', 'ad10', 'italy', 'pulsar', 'us', 'us', 'netflix', 'new zealand', 'new zealand', 'india', 'south island', 'm3', 'aruba', 'uk', 'randolph county', 'arkansas', 'iraq', 'india', 'mexico', 'answy', 'chicago', 'accidentaly', 'midwest', 'colorado', 'mm', 'youeiferundehre', 'youffefryn', 'dang', 'dmcas', 'the moon', 'coma', 'hahaha', 'arkansas', 'mexico', 'egypt', 'mpcc', 'houston', 'france', 'paris', 'pulsar', 'nova', 'suffix', 'chile', 'daytona beach', 'india', 'astro', 'atlantic', 'titan', 'south america', 'titan', 'india', 'titan', 'canada', 'titan', 'titan', 'uk', 'mount mount', 'uk', 'uk', 'fermi', 'north america', 'ngc6888', 'north america', 'rome', 'india', 'southeast asia', 'mexico', 'spain', 'netherlands', 'periodicaly', 'us', 'italy', 'egypt', 'nile', 'nova', 'nova', 'nova', 'nova', 'australia', 'ohio', 'cincinnati', 'cincinnati', 'netherlands', 'ww2 airstrip', 'netherlands', 'new zealand', 'new zealand', 'texas', 'colorado', 'kochab', 'gta5', 'bay state', 'china', 'china', 'orange moon', 'serpens', 'south island', 'new zealand', 'australia', 'chicago', 'chicago', 'massachusetts', 'boston', 'dobsonian mount', 'colorado', 'atlantic', 'portugal', 'portugal', 'note20', 'ocean county', 'earth moon', 'earth', 'paris', 'paris', 'massachusetts', 'mount mount', 'nuh', 'texas', 'denver', 'texas', 'michigan', 'maryland', 'arizona', 'michigan', 'us', 'canada', 'virginia', 'west virginia', 'earth', 'north east', 'south america', 'south america', 'new zealand', 'south africa', 'america', 'russia']\n"
     ]
    }
   ],
   "source": [
    "rec_loc_s[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HelperFunctions import write_to_text_file\n",
    "\n",
    "write_to_text_file(rec_loc_s, \"NER_loc_comments_sentences\")\n",
    "#write_to_text_file(rec_loc_s, \"NER_loc__submissions_sentences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_w(file_path, model):\n",
    "    \"\"\"\n",
    "    Read words from a file and process them using spaCy's NER.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the input text file.\n",
    "    - model: The spaCy NLP model.\n",
    "    \n",
    "    Returns:\n",
    "    - recommended_locs (list): List of extracted locations.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    recommended_locs = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            word = line.strip()  # Remove leading/trailing whitespace\n",
    "            if word:  # Skip empty lines\n",
    "                i += 1\n",
    "                # Process the word with spaCy\n",
    "                doc = model(word)\n",
    "                # Extract locations\n",
    "                loc = get_locations_from_doc(doc)\n",
    "                if loc:\n",
    "                    recommended_locs.extend(loc)\n",
    "                if i == 60000:\n",
    "                    break\n",
    "    return recommended_locs\n",
    "\n",
    "def get_locations_from_doc(doc):\n",
    "    \"\"\"\n",
    "    Extract location-related entities from a spaCy Doc object.\n",
    "    \n",
    "    Parameters:\n",
    "    - doc: A spaCy Doc object.\n",
    "    \n",
    "    Returns:\n",
    "    - locations (list): List of location names identified in the text.\n",
    "    \"\"\"\n",
    "    location_labels = {\"LOC\", \"GPE\", \"FAC\"}\n",
    "    return [ent.text for ent in doc.ents if ent.label_ in location_labels]\n",
    "\n",
    "rec_loc_w = process_file_w(\"preprocessed_comments_words\",model_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_text_file(rec_loc_w, \"NER_loc_comments_words\")\n",
    "#write_to_text_file(rec_loc_w, \"NER_loc_submissions_words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['florida', 'georgia', 'arizona', 'london', 'scotland', 'florida', 'arizona', 'northeast', 'strip', 'asi120mm', 'coma', 'at60ed', 'at60ed', 'canada', 'california', 'alaska', 'california', 'triton', 'michigan', 'michigan', 'michigan', 'newton', 'newton', 'alabama', 'massachusetts', 'mexico', 'pulsar']\n"
     ]
    }
   ],
   "source": [
    "print(rec_loc_w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openap-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
